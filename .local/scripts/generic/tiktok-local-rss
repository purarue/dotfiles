#!/usr/bin/env python3
# uses yt-dlp to download recent tiktoks from
# specific users
#
# creates RSS feeds for each user
#
# allows you to prune old videos after they're
# some days old

import os
import time
import json
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Sequence

import click
import platformdirs
from yt_dlp import YoutubeDL
from feedgen.feed import FeedGenerator
from mlength import MediaFile, display_duration
from yt_dlp.utils import DownloadError


filedir = Path(platformdirs.user_cache_dir("tiktok-local-rss"))

if not filedir.exists():
    mkdir = filedir.mkdir()


def userinfo_file(name: str) -> Path:
    return filedir / name / "info.json"


DOWNLOAD_RECENT = 10


def download_user(name: str) -> None:
    assert name != "rss"
    userfile = userinfo_file(name)
    if not userfile.parent.exists():
        userfile.parent.mkdir()
    data: dict[str, Any] = {}
    if userfile.exists():
        data = json.loads(userfile.read_text())

    assert isinstance(data, dict)

    ydl_opts = {
        "quiet": False,
        "no_warnings": False,
        "outtmpl": os.path.join(userfile.parent, "%(id)s-%(title)s.mp4"),
        "playlistend": DOWNLOAD_RECENT,
        "download_archive": userfile.parent / "downloaded.txt",
        "lazy_playlist": True,
    }

    time.sleep(5)
    with YoutubeDL(ydl_opts) as ydl:
        try:
            info = ydl.extract_info(f"https://www.tiktok.com/@{name}")
            assert isinstance(info, dict)

            for entry in info["entries"]:
                assert isinstance(entry["id"], str)
                data[entry["id"]] = {
                    k: v
                    for k, v in entry.items()
                    if k not in {"id", "formats", "cookies", "requested_downloads"}
                }

        except DownloadError as e:
            click.secho(f"failed to download {name} | {e}", err=True, fg="red")
            return

    with open(userfile, "w") as f:
        json.dump(data, f, indent=2)


def glob_for_vid(video_dir, startswith: str) -> Path:
    local_file = list(video_dir.glob(f"{startswith}-*"))

    if len(local_file) == 0:
        raise RuntimeError(f"no files found for {startswith}")
    assert len(local_file) == 1
    assert local_file[0].suffix == ".mp4", f"file ext is {local_file[0].suffix}"

    return local_file[0]


def prune_old_files(name: str, prune_older_than_days: float, debug: bool) -> None:
    datafile = userinfo_file(name)
    if not datafile.exists():
        return
    video_dir = datafile.parent

    data = json.loads(datafile.read_text())

    videos: dict[str, datetime] = {
        k: datetime.fromtimestamp(v["timestamp"], tz=timezone.utc)
        for k, v in data.items()
    }

    videos = dict(sorted(videos.items(), key=lambda x: x[1], reverse=True))
    for i, (name, timestamp) in enumerate(videos.items()):
        try:
            file = glob_for_vid(video_dir, name)
        except RuntimeError:
            continue
        if i <= DOWNLOAD_RECENT:
            if debug:
                click.echo(
                    f"skipping: latest downloaded files ({i}/{DOWNLOAD_RECENT}) | {file}, ",
                    err=True,
                )
            continue

        days_ago = (datetime.now(tz=timezone.utc) - timestamp).days
        if days_ago > prune_older_than_days:
            click.echo(
                f"pruning: released {days_ago}>{prune_older_than_days} days ago | {file}",
                err=True,
            )
            file.unlink()
            del data[name]
        else:
            if debug:
                click.echo(
                    f"keeping: released {days_ago}<={prune_older_than_days} days ago | {file}",
                    err=True,
                )

    datafile.write_text(json.dumps(data, indent=2))


@click.group()
def main() -> None:
    pass


users_file = (
    Path(os.environ.get("XDG_DOCUMENTS_DIR", os.path.expanduser("~/Documents")))
    / "tiktok.txt"
)
assert (
    users_file.exists()
), f"cannot find tiktok user file {users_file}, should have one username per line"
USERS = []
for user in users_file.read_text().splitlines():
    if user.strip().startswith("#"):
        continue
    USERS.append(user.strip().lstrip("@"))


def generate_rss_file(user: str, rss_dir: Path) -> None:
    downloaded = filedir / user / "downloaded.txt"
    if not downloaded.exists():
        click.echo(
            f"no downloaded videos for {user}, skipping RSS generation", err=True
        )
        return
    feed = FeedGenerator()
    feed.id(user)
    feed.title(f"TikTok Local: {user}")
    feed.link(href=f"https://www.tiktok.com/@{user}")
    feed.description(user)

    datafile = userinfo_file(user)
    if not datafile.exists():
        return
    video_dir = datafile.parent
    for id, info in json.loads(datafile.read_text()).items():
        if "url" in info:
            entry = feed.add_entry()
            entry.id(id)
            entry.author({"name": info["channel"]})
            entry.title(f"{user} | {info["title"]}")
            entry.link(href=info["webpage_url"])
            entry.published(datetime.fromtimestamp(info["timestamp"], tz=timezone.utc))
            try:
                video_file = glob_for_vid(video_dir, id)
            except RuntimeError:
                continue

            entry.enclosure(
                url=f"file://{video_file}",
                type="video/mp4",
                length=video_file.stat().st_size,
            )

            mf = MediaFile(video_file, Path("~/.cache/mlength").expanduser())
            duration = mf.cached_duration("ffprobe")
            disp = display_duration(duration, display="human", path=None)

            # remove hours/minutes if its not that long
            while disp.startswith("00:"):
                disp = disp[3:]

            entry.description(f"[{disp}] {info["description"]}")

    feed.rss_file(rss_dir / f"{user}.xml")


@main.command(short_help="generate RSS files")
def rss() -> None:
    """
    Generate RSS files for each users
    """
    rss_files = filedir / "rss"
    if not rss_files.exists():
        rss_files.mkdir()

    for user in USERS:
        generate_rss_file(user, rss_files)


@main.command(short_help="prune videos older than x days")
@click.option("-d", "--debug", is_flag=True, default=False)
@click.argument("COUNT", type=int, default=30)
def prune(count: int, debug: bool) -> None:
    """
    Prune videos older than x days
    """
    for user in USERS:
        prune_old_files(user, count, debug=debug)


@main.command(short_help="download videos")
@click.argument("USER", nargs=-1, required=False)
def download(user: Sequence[str]) -> None:
    """
    Download recent videos for all users
    """
    if user:
        if user[0] not in USERS:
            raise click.ClickException(f"unknown user {user[0]}")
    for u in USERS:
        if user and user[0] != u:
            continue
        download_user(u)


if __name__ == "__main__":
    main()
